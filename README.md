# FAQ Suggester API ğŸ¤–ğŸ’¬  
_Muestra sugerencias (suggest) de la base de conocimientos a partir de una pregunta (query)_

![FastAPI](https://img.shields.io/badge/FastAPI-0.115.x-009688?logo=fastapi&logoColor=white)
![ChromaDB](https://img.shields.io/badge/ChromaDB-1.0.x-673ab7)
![Ollama](https://img.shields.io/badge/Ollama-local-blue)
![Licence](https://img.shields.io/badge/Licence-MIT-green)

---

## ğŸ“ PropÃ³sito

Automatizar la labor de los asesores que atienden solicitudes ciudadanas:

* **RecuperaciÃ³n inteligente** de la mejor respuesta entre las FAQ (con embeddings semÃ¡nticos).
* **Aprendizaje activo** â€”si la similitud es bajaâ€” la nueva respuesta se agrega sin reiniciar el servicio.
* **HistÃ³rico auditable** de todas las consultas y respuestas enviadas.
* Sin base de datos externa: todo persiste en archivos JSON y un vector-store embebido.

---

## ğŸ› ï¸ TecnologÃ­as principales

| Capa | TecnologÃ­a | Rol |
|------|------------|-----|
| API REST | **FastAPI** + Uvicorn | End-points `/suggest`, `/history`, `/feedback` |
| Vector-store | **ChromaDB 1.x** | Almacena embeddings persistentes |
| Embeddings | **`nomic-embed-text`** (Ollama) | ConversiÃ³n de texto â†’ vector |
| LLM | **`gemma3:12b`** (Ollama) | Genera la â€œprÃ³xima preguntaâ€ para pruebas |
| UI opcional | **Streamlit** | Chat + sugerencias + tabla de historial |
| Container | Docker & Docker Compose | Despliegue reproducible |

---

## ğŸ“ Estructura del Proyecto

```text
ğŸ“faq_suggester_api/
â”œâ”€â”€ ğŸ“app/                        # CÃ³digo de la API FastAPI
â”‚   â”œâ”€â”€ ğŸ“api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ routes.py             # Endpoints: /suggest, /history, /feedback
â”‚   â”œâ”€â”€ ğŸ“config/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ settings.py           # Variables de entorno y paths
â”‚   â”œâ”€â”€ ğŸ“llm/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ question_generator.py
â”‚   â”œâ”€â”€ ğŸ“models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ schemas.py
â”‚   â”œâ”€â”€ ğŸ“repository/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ history_repo.py
â”‚   â”œâ”€â”€ ğŸ“services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ faq_service.py
â”‚   â”œâ”€â”€ ğŸ“logging_config.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ ğŸ“chroma_langchain_db/        # Vector-store persistente (Chroma)
â”‚   â””â”€â”€ ...                       # Archivos creados en tiempo de ejecuciÃ³n
â”‚
â”œâ”€â”€ ğŸ“data/                       # Base de conocimiento & historial
â”‚   â”œâ”€â”€ faq.json
â”‚   â””â”€â”€ history.json
â”‚
â”œâ”€â”€ ğŸ“prompts/                     # Plantillas de prompts auxiliares
â”‚   â””â”€â”€ question_generator_system.txt
â”‚
â”œâ”€â”€ ğŸ“tests/                       # Pruebas unitarias / integraciÃ³n
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_faq_service.py
â”‚   â””â”€â”€ test_routes.py
â”‚
â”œâ”€â”€ ğŸ“ui/                         # Cliente Streamlit (opcional)
â”‚   â””â”€â”€ streamlit_app.py
â”‚
â”œâ”€â”€ main.py                       # Wrapper / entry-point
â”œâ”€â”€ Dockerfile                    # Build de la imagen (API + UI)
â”œâ”€â”€ docker-compose.yml            # OrquestaciÃ³n: API, UI, Ollamaâ€¦
â”œâ”€â”€ Makefile                      # Atajos para lint, test, buildâ€¦
â”œâ”€â”€ pyproject.toml                # Dependencias (uv / PDM / Poetry)
â”œâ”€â”€ uv.lock                       # Lockfile reproducible para uv
â”œâ”€â”€ requirements.txt              # SÃ³lo para la imagen Docker slim
â”œâ”€â”€ .python-version               # VersiÃ³n fijada (pyenv)
â””â”€â”€ .gitignore                    # Reglas globales
```

---

## ğŸ¯ Prerequisitos
Antes de iniciar el proyecto, asegÃºrate de tener instalado lo siguiente:

- **uv**: Un administrador de paquetes de Python rÃ¡pido, escrito en Rust. Lo usaremos para gestionar las dependencias del proyecto.
  Sitio web oficial: [https://docs.astral.sh/uv](https://docs.astral.sh/uv/getting-started/installation/)
- **Ollama**: Una herramienta para ejecutar modelos de lenguaje grandes localmente. NecesitarÃ¡s descargar e instalar Ollama para poder usar los modelos de IA.
  Sitio web oficial: [Ollama](https://ollama.com/)
- **Chocolatey** (Solo para Windows): Un administrador de paquetes para Windows. Si usas Windows, Chocolatey facilita la instalaciÃ³n de herramientas como make.
  Sitio web oficial: [Chocolatey](https://chocolatey.org/install)
- **make**: Una utilidad que controla la generaciÃ³n de ejecutables y otros archivos a partir de los archivos fuente de un programa. Lo usaremos para simplificar el proceso de inicio del proyecto.

---

## ğŸš€ InstalaciÃ³n

### 1. ğŸ¤– Tener un modelo de IA disponible

Necesitas tener corriendo **Ollama local**
Instala un LLM en local con el siguiente comando para **nomic-embed-text**
```bash
ollama run gemma3:12b
```
Instala un modelo de embeddings en local con el siguiente comando para **gemma3:12b**
```bash
ollama pull nomic-embed-text
```
Listo ya tienes lista una gran parte del trabajo, ahora puedes desde tu terminal ver los modelos disponibles con:
```bash
ollama list
```

### 2. Demo en 3 comandos (con Docker Compose ğŸ³)

```bash
git clone https://github.com/BMunoz14/faq_suggester_api.git
cd faq-suggester-api
docker compose up --build
```

### 3. Segunda opcion Demo en local (sin Docker)

Clona el repositorio
```bash
git clone https://github.com/BMunoz14/faq_suggester_api.git
cd faq-suggester-api
```
Instalar dependencias con **uv**
```bash
uv sync
```
Ejecuta desde la terminal ubicÃ¡ndose en el proyecto **Para iniciar la API REST**
```bash
make dev
```
Opcional si quieres probar desde el navegador en `http://localhost:8501/`, abre otra terminal en el proyecto y ejecuta **Para probar la API desde Streamlit**
```bash
make web
```
![image](https://github.com/user-attachments/assets/aeb8c7da-cc19-4954-ae69-02e6c6ab114b)

---

## faq_suggester_api funcionando

### API Swagger en `http://localhost:8000/docs`

POST /suggest
![image](https://github.com/user-attachments/assets/a7794559-0b76-418d-9101-d7d07d6fed9a)

GET /history
![image](https://github.com/user-attachments/assets/caaaebf9-533f-44be-af15-eeb9243746dd)

POST /feedback
![image](https://github.com/user-attachments/assets/11c0588a-e9b8-4289-9497-a1c3d2ca77bb)

### API desde Streamlit `(http://localhost:8501)`

![image](https://github.com/user-attachments/assets/9e508760-1850-460c-970e-76db2a5dab28)

![image](https://github.com/user-attachments/assets/ac32a377-090e-42d5-9e35-148d4cc93d9c)

---
